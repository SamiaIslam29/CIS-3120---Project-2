# -*- coding: utf-8 -*-
"""Project #2 - Part A Question #2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12ddNC3RxwS4nIoBgYFWCxPPzfZn0SDPj

Question #2
"""

# Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Step 1 & 2: Load the dataset into pandas DataFrame
data1 = pd.read_csv('HousePrice.csv')
data2 = pd.read_csv('HousePrice2.csv')

# Combine both datasets for analysis (if necessary)
data = pd.concat([data1, data2], ignore_index=True)

# Replace NaN values with column means for numeric columns
data = data.copy()  # Avoid altering the original data
data.fillna(data.mean(numeric_only=True), inplace=True)

# Step 2: Visualizations
# 2.1 Distribution of SalePrice
plt.figure(figsize=(8, 5))
sns.histplot(data['SalePrice'], kde=True, bins=30)
plt.title('Sale Price Distribution')
plt.xlabel('Sale Price')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

# 2.2 Correlation matrix (fixing NaN issues)
# Select only numeric columns
numeric_data = data.select_dtypes(include=np.number)
if numeric_data.empty:
    print("No numeric columns with valid data available for correlation matrix.")
else:
    plt.figure(figsize=(12, 10))
    correlation_matrix = numeric_data.corr()
    sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', linewidths=0.5)
    plt.title('Correlation Matrix')
    plt.tight_layout()
    plt.show()

# 2.3 Boxplot of SalePrice vs Overall Quality
plt.figure(figsize=(8, 5))
data['OverallQual'] = pd.to_numeric(data['OverallQual'], errors='coerce')
sns.boxplot(x='OverallQual', y='SalePrice', data=data)
plt.title('Sale Price by Overall Quality')
plt.xlabel('Overall Quality')
plt.ylabel('Sale Price')
plt.tight_layout()
plt.show()

# 2.4 Scatter plot between SalePrice and GrLivArea
plt.figure(figsize=(8, 5))
sns.scatterplot(x=data['GrLivArea'], y=data['SalePrice'])
plt.title('Living Area vs Sale Price')
plt.xlabel('Living Area (sq ft)')
plt.ylabel('Sale Price')
plt.tight_layout()
plt.show()

# Step 4: Data Cleaning (remove NaNs and duplicates)
for col in data.select_dtypes(include=np.number).columns:
    data[col] = data[col].fillna(data[col].mean()) # or data[col].median()

for col in data.select_dtypes(include=['object']).columns:
    # Check if the mode is empty before accessing element 0
    mode = data[col].mode()
    if not mode.empty:
        data[col] = data[col].fillna(mode[0])
    else:
        # Handle the case where mode is empty (e.g., fill with a placeholder)
        data[col] = data[col].fillna('Unknown')  # Or any other suitable value

# Remove duplicates if necessary
data = data.drop_duplicates()

import pandas as pd
from sklearn.model_selection import train_test_split

# Load the dataset
data = pd.read_csv('HousePrice2.csv')

# Inspect the dataset
print("Dataset columns:", data.columns)
print(data.head())
print("Dataset info:")
print(data.info())

# Step 5: Split into training and testing sets (70:30)
# Ensure 'SalePrice' exists in the dataset
if 'SalePrice' not in data.columns:
    raise ValueError("Column 'SalePrice' not found in the dataset.")

# Drop rows with missing 'SalePrice' values and ensure features are valid
data = data.dropna(subset=['SalePrice'])
X = data.drop(columns=['SalePrice'], errors='ignore')  # Features
y = data['SalePrice']  # Target

# Check if X and y are not empty
if X.empty:
    print("Feature data (X) is empty.")
if y.empty:
    print("Target data (y) is empty.")
if X.empty or y.empty:
    raise ValueError("Feature or target data is empty. Please check the dataset.")

# Check for missing values in features
print("Missing values in features (X):")
print(X.isnull().sum())

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print("Training and testing sets created successfully.")
print(f"Training set size: {X_train.shape}, {y_train.shape}")
print(f"Testing set size: {X_test.shape}, {y_test.shape}")

# Step 6: Standardize the features (if necessary)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 7: Fit the Linear Regression model
model = LinearRegression()
model.fit(X_train_scaled, y_train)

# Step 8: Make predictions on test data
y_pred = model.predict(X_test_scaled)

# Step 9: Assess the model
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print(f"R-squared: {r2:.4f}")
print(f"Mean Absolute Error: {mae:.2f}")
print(f"Mean Squared Error: {mse:.2f}")
print(f"Root Mean Squared Error: {rmse:.2f}")

# Visualizing predictions vs actual values
plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.title('Predicted vs Actual Prices')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.show()